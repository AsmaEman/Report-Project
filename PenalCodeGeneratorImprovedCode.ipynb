{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec6395b7",
   "metadata": {
    "id": "ec6395b7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cf41880",
   "metadata": {
    "id": "5cf41880"
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "TMBQ5BsUm7Ee",
   "metadata": {
    "id": "TMBQ5BsUm7Ee"
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_files=[\"calcrim_2023_edition.pdf\"])\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c726dc51",
   "metadata": {
    "id": "c726dc51"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "# !pip install llama-index\n",
    "\n",
    "from llama_index import LLMPredictor, GPTVectorStoreIndex, PromptHelper\n",
    "\n",
    "\n",
    "# define LLM\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.1, model_name=\"text-embedding-ada-002\"))\n",
    "\n",
    "max_input_size = 4896\n",
    "num_outputs = 512\n",
    "max_chunk_overlap = 20\n",
    "chunk_size_limit = 681\n",
    "prompt_helper = PromptHelper(max_input_size, num_outputs, chunk_overlap_ratio=0.1, chunk_size_limit=chunk_size_limit)\n",
    "\n",
    "custom_LLM_index = GPTVectorStoreIndex(\n",
    "    documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f501b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# open a file, where you ant to store the data\n",
    "# file = open('LLM_Index', 'wb')\n",
    "\n",
    "# # dump information to that file\n",
    "# pickle.dump(custom_LLM_index, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842d9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "file = open('LLM_Index', 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "data = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a0e830",
   "metadata": {
    "id": "65a0e830"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, api_key, index):\n",
    "        self.index = index\n",
    "        openai.api_key = api_key\n",
    "\n",
    "    def generate_response_from_text(self, user_input):\n",
    "        prompt = f\"\"\"\n",
    "        Incident Summary: {user_input}\n",
    "\n",
    "                As a criminal law expert, understand the incident and try to find relevant penal code.\n",
    "\n",
    "                Only return the penal code. Do not write any filler text.\n",
    "\n",
    "                If you can't find the penal code, return \"N/A\".\n",
    "        \"\"\"\n",
    "#         prompt = f\"User: {user_input} tell only one best matching penal code for the crime in this report?\"\n",
    "        query_engine = self.index.as_query_engine()  # Use self.index instead of index\n",
    "        response = query_engine.query(prompt)  # Use prompt instead of user_input\n",
    "\n",
    "        message = {\"content\": response.response}\n",
    "        return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24576df3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "24576df3",
    "outputId": "6cd38fdd-15d8-41fa-e6e0-827fb37392f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to upload a file? (yes/no): yes\n",
      "Bot: 245(a)(1)â€“(4), (b)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36332/660317988.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mupload_option\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Do you want to upload a file? (yes/no): \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupload_option\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"no\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             )\n\u001b[1;32m-> 1006\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Swap out your index below for whatever knowledge base you want\n",
    "bot = Chatbot(\"api-key\", index=data)\n",
    "\n",
    "# !pip install python-docx\n",
    "from docx import Document\n",
    "# from google.colab import files\n",
    "import io\n",
    "\n",
    "def upload_file():\n",
    "    uploaded_files = files.upload()\n",
    "\n",
    "    if uploaded_files:\n",
    "        file_content = list(uploaded_files.values())[0]\n",
    "        return file_content\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "while True:\n",
    "    upload_option = input(\"Do you want to upload a file? (yes/no): \").lower()\n",
    "\n",
    "    if upload_option == \"no\":\n",
    "        break\n",
    "\n",
    "    if upload_option == \"yes\":\n",
    "        file_content = 'Sample Reports/Form C O22 205 0026.docx'\n",
    "        if file_content:\n",
    "            try:\n",
    "                # Use python-docx to read the document from bytes\n",
    "                doc = Document(file_content)\n",
    "\n",
    "                # Extract text from DOCX\n",
    "                paragraphs = [paragraph.text for paragraph in doc.paragraphs]\n",
    "                user_input = \"\\n\".join(paragraphs)\n",
    "                user_input = \"\"\"\n",
    "                Physical assault with injuries\n",
    "\n",
    "                \"\"\"\n",
    "                # Generate a response using a 'bot' object\n",
    "                response = bot.generate_response_from_text(user_input)\n",
    "                print(f\"Bot: {response['content']}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error: Unable to read the Word document content. {str(e)}\")\n",
    "        else:\n",
    "            print(\"File upload canceled or failed. Please try again.\")\n",
    "    else:\n",
    "        print(\"Invalid option. Please enter 'yes' or 'no'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef39542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
